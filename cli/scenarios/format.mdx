---
title: Scenario Format
description: Learn the YAML scenario file format
---

# Scenario Format

ArtemisKit scenarios are defined in YAML files. This page covers the complete schema.

## Basic Structure

```yaml
name: my-evaluation
description: Description of this evaluation
provider: openai
model: gpt-5

cases:
  - id: test-case-id
    prompt: "Your prompt here"
    expected:
      type: contains
      values:
        - "expected text"
      mode: any
```

## Top-Level Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `name` | string | Yes | Name of the scenario |
| `description` | string | No | Human-readable description |
| `version` | string | No | Scenario version (default: "1.0") |
| `provider` | string | No | LLM provider (openai, azure-openai, vercel-ai, anthropic, etc.) |
| `model` | string | No | Model name |
| `providerConfig` | object | No | Provider-specific configuration overrides |
| `temperature` | number | No | Sampling temperature (0-2) |
| `seed` | number | No | Random seed for reproducibility |
| `maxTokens` | number | No | Maximum tokens in response |
| `tags` | array | No | Tags for filtering |
| `variables` | object | No | Key-value pairs for variable substitution |
| `setup` | object | No | Setup configuration (system prompt, functions) |
| `cases` | array | Yes | List of test cases |
| `teardown` | object | No | Teardown configuration |
| `redaction` | object | No | PII/sensitive data redaction configuration |

## Test Case Object

Each test case requires an `id` and a `prompt`:

```yaml
cases:
  - id: greeting-test          # Required: unique identifier
    name: Greeting Test        # Optional: human-readable name
    description: "Tests..."    # Optional: description
    prompt: "Say hello"        # Required: the prompt (string or message array)
    expected:                  # Required: expectation definition
      type: contains
      values: ["hello"]
      mode: any
    tags: [basic, regression]  # Optional: tags for filtering
    timeout: 30000             # Optional: timeout in milliseconds
    retries: 0                 # Optional: number of retries (default: 0)
    provider: openai           # Optional: override scenario provider
    model: gpt-5             # Optional: override scenario model
    variables:                 # Optional: case-level variables
      name: "Alice"
```

## Provider Config

Override provider settings at the scenario level:

```yaml
name: with-provider-config
provider: azure-openai
model: gpt-5

providerConfig:
  resourceName: my-azure-resource
  deploymentName: my-deployment
  apiVersion: 2024-02-15-preview

cases:
  - id: example
    prompt: "Hello"
    expected:
      type: contains
      values: ["hello"]
      mode: any
```

## Setup Object

Configure the system prompt and optional functions:

```yaml
setup:
  systemPrompt: "You are a helpful assistant."
  functions: []  # Optional: function definitions for function calling
```

## Variables

Use `{{variable}}` syntax for dynamic content. Variables can be defined at the scenario level or case level:

```yaml
name: variable-example
variables:
  product: "ArtemisKit"
  version: "1.0"

cases:
  - id: with-variables
    prompt: "Tell me about {{product}} version {{version}}"
    expected:
      type: contains
      values: ["{{product}}"]
      mode: any
    variables:
      version: "2.0"  # Overrides scenario-level variable
```

Variables support strings, numbers, and booleans:

```yaml
variables:
  name: "Alice"      # string
  count: 42          # number
  enabled: true      # boolean
```

## Single-Turn Prompts

For simple single-turn interactions, use a string prompt:

```yaml
cases:
  - id: simple-test
    prompt: "What is 2 + 2?"
    expected:
      type: contains
      values: ["4"]
      mode: any
```

## Multi-Turn Conversations

For multi-turn conversations, use an array of messages in the `prompt` field:

```yaml
cases:
  - id: multi-turn-test
    prompt:
      - role: user
        content: "My name is Alice"
      - role: assistant
        content: "Nice to meet you, Alice!"
      - role: user
        content: "What is my name?"
    expected:
      type: contains
      values: ["Alice"]
      mode: any
```

The system prompt from `setup.systemPrompt` is automatically prepended to multi-turn conversations.

### Message Object

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `role` | string | Yes | One of: `system`, `user`, `assistant` |
| `content` | string | Yes | The message content |

## Complete Example

```yaml
name: customer-support-bot
description: Evaluation suite for customer support chatbot
provider: openai
model: gpt-5
seed: 42

variables:
  company: "TechCorp"

setup:
  systemPrompt: "You are a friendly customer support agent for {{company}}."

cases:
  - id: greeting
    name: Greeting Test
    description: Test greeting responses
    tags: [basic, regression]
    prompt: "Hello!"
    expected:
      type: contains
      values:
        - "hello"
        - "hi"
        - "welcome"
      mode: any

  - id: product-inquiry
    name: Product Inquiry
    description: Test product information
    tags: [product, qa]
    prompt: "What products do you sell?"
    expected:
      type: llm_grader
      rubric: "Response mentions at least 2 product categories and is helpful"
      threshold: 0.7

  - id: context-retention
    name: Context Retention Test
    description: Test that the bot remembers context
    tags: [advanced]
    prompt:
      - role: user
        content: "I'm interested in your premium plan"
      - role: assistant
        content: "Great choice! Our premium plan includes..."
      - role: user
        content: "How much does it cost?"
    expected:
      type: contains
      values:
        - "price"
        - "cost"
        - "$"
      mode: any
```

## Redaction Configuration

Configure PII/sensitive data redaction at the scenario level:

```yaml
name: with-redaction
provider: openai
model: gpt-5

redaction:
  enabled: true
  patterns:
    - email
    - phone
    - credit_card
    - ssn
    - api_key
  redactPrompts: true
  redactResponses: true
  replacement: "[REDACTED]"

cases:
  - id: example
    prompt: "Contact me at user@example.com"
    expected:
      type: contains
      values: ["contact"]
      mode: any
```

### Redaction Fields

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `enabled` | boolean | `false` | Enable/disable redaction |
| `patterns` | array | Default patterns | Built-in patterns or custom regex |
| `redactPrompts` | boolean | `true` | Redact prompts in output |
| `redactResponses` | boolean | `true` | Redact responses in output |
| `redactMetadata` | boolean | `false` | Redact metadata fields |
| `replacement` | string | `[REDACTED]` | Replacement text |

### Built-in Patterns

Common patterns (used in CLI examples):
- `email` — Email addresses
- `phone` — Phone numbers
- `credit_card` — Credit card numbers
- `ssn` — Social Security Numbers
- `api_key` — API keys and tokens

Additional patterns available:
- `ipv4` — IPv4 addresses
- `jwt` — JWT tokens
- `aws_key` — AWS access keys
- `secrets` — Generic secrets (password=, secret=, etc.)

You can also use custom regex patterns in the `patterns` array.

## Provider Override

You can override provider settings at the scenario or case level:

```yaml
name: provider-override-example
provider: openai
model: gpt-5

cases:
  - id: test-with-different-model
    prompt: "Hello"
    provider: anthropic
    model: claude-3-5-sonnet-20241022
    expected:
      type: contains
      values: ["hello"]
      mode: any
```

## See Also

- [Expectations](/docs/cli/scenarios/expectations/) — Learn about all expectation types
- [Run Command](/docs/cli/commands/run/) — Execute scenarios
