---
title: OpenRouter
description: Configure ArtemisKit with OpenRouter
---

# OpenRouter Provider

Use ArtemisKit with [OpenRouter](https://openrouter.ai/) to access multiple LLM providers through a single API.

## Setup

### 1. Get API Key

Get your API key from [OpenRouter](https://openrouter.ai/keys).

### 2. Set Environment Variable

```bash
export OPENROUTER_API_KEY="sk-or-..."
```

### 3. Configure Scenario

```yaml
name: my-test
provider: openrouter
model: openai/gpt-5.1

cases:
  - id: example
    prompt: "Hello"
    expected:
      type: contains
      values: ["hello"]
      mode: any
```

## Model Format

OpenRouter uses the format `provider/model`:

```
openai/gpt-5.1
anthropic/claude-3-5-sonnet
google/gemini-pro
meta-llama/llama-3-70b-instruct
```

## Popular Models

| Model | Description |
|-------|-------------|
| `openai/gpt-5.1` | OpenAI GPT-5.1 |
| `anthropic/claude-3-5-sonnet` | Anthropic Claude 3.5 Sonnet |
| `google/gemini-pro` | Google Gemini Pro |
| `meta-llama/llama-3-70b-instruct` | Meta Llama 3 70B |
| `mistralai/mistral-large` | Mistral Large |

See the full [OpenRouter model list](https://openrouter.ai/models) for all available models.

## Config File

Configure OpenRouter in your `artemis.config.yaml`:

```yaml
provider: openrouter
model: openai/gpt-5.1

providers:
  openrouter:
    apiKey: ${OPENROUTER_API_KEY}
    timeout: 60000
    maxRetries: 2
```

## Use Cases

OpenRouter is ideal for:

- **Model comparison** — Test the same scenario across different providers
- **Cost optimization** — Route to cheaper models for specific tasks
- **Fallback providers** — Access backup models if primary is unavailable

## See Also

- [OpenAI](/docs/cli/providers/openai/)
- [Anthropic](/docs/cli/providers/anthropic/)
- [Scenario Format](/docs/cli/scenarios/format/)
